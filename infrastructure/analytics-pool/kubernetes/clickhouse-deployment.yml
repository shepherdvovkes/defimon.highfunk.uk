apiVersion: apps/v1
kind: Deployment
metadata:
  name: clickhouse
  namespace: analytics
  labels:
    app: clickhouse
    pool: analytics
spec:
  replicas: 1
  selector:
    matchLabels:
      app: clickhouse
  template:
    metadata:
      labels:
        app: clickhouse
        pool: analytics
    spec:
      containers:
      - name: clickhouse
        image: clickhouse/clickhouse-server:latest
        ports:
        - containerPort: 8123
          name: http
        - containerPort: 9000
          name: native
        env:
        - name: CLICKHOUSE_DB
          value: "analytics"
        - name: CLICKHOUSE_USER
          valueFrom:
            secretKeyRef:
              name: clickhouse-secrets
              key: username
        - name: CLICKHOUSE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: clickhouse-secrets
              key: password
        - name: CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT
          value: "1"
        volumeMounts:
        - name: clickhouse-data
          mountPath: /var/lib/clickhouse
        - name: clickhouse-config
          mountPath: /etc/clickhouse-server/config.d
        - name: clickhouse-init
          mountPath: /docker-entrypoint-initdb.d
        resources:
          requests:
            memory: "4Gi"
            cpu: "1000m"
          limits:
            memory: "8Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /ping
            port: 8123
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ping
            port: 8123
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: clickhouse-data
        persistentVolumeClaim:
          claimName: clickhouse-pvc
      - name: clickhouse-config
        configMap:
          name: clickhouse-config
      - name: clickhouse-init
        configMap:
          name: clickhouse-init
---
apiVersion: v1
kind: Service
metadata:
  name: clickhouse-service
  namespace: analytics
spec:
  selector:
    app: clickhouse
  ports:
  - protocol: TCP
    port: 8123
    targetPort: 8123
    name: http
  - protocol: TCP
    port: 9000
    targetPort: 9000
    name: native
  type: ClusterIP
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: clickhouse-pvc
  namespace: analytics
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 200Gi
  storageClassName: hcloud-volumes
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: clickhouse-config
  namespace: analytics
data:
  custom.xml: |
    <clickhouse>
        <max_memory_usage>6GB</max_memory_usage>
        <max_memory_usage_for_user>5GB</max_memory_usage_for_user>
        <max_memory_usage_for_all_queries>4GB</max_memory_usage_for_all_queries>
        <max_concurrent_queries>100</max_concurrent_queries>
        <max_threads>8</max_threads>
        <background_pool_size>16</background_pool_size>
        <background_schedule_pool_size>16</background_schedule_pool_size>
        <keep_alive_timeout>3</keep_alive_timeout>
        <max_connections>4096</max_connections>
        <max_open_files>262144</max_open_files>
        <tcp_keep_alive_timeout>300</tcp_keep_alive_timeout>
        <tcp_nodelay>1</tcp_nodelay>
        <listen_host>0.0.0.0</listen_host>
        <http_port>8123</http_port>
        <tcp_port>9000</tcp_port>
        <interserver_http_port>9009</interserver_http_port>
        <interserver_http_host>0.0.0.0</interserver_http_host>
        <mark_cache_size>5368709120</mark_cache_size>
        <uncompressed_cache_size>8589934592</uncompressed_cache_size>
        <path>/var/lib/clickhouse/</path>
        <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
        <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>
        <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>
        <user_directories>
            <users_xml>
                <path>/etc/clickhouse-server/users.xml</path>
            </users_xml>
        </user_directories>
        <default_profile>default</default_profile>
        <default_database>default</default_database>
        <timezone>UTC</timezone>
        <remote_servers>
        </remote_servers>
        <include_from>/etc/clickhouse-server/config.d/*.xml</include_from>
    </clickhouse>
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: clickhouse-init
  namespace: analytics
data:
  init.sql: |
    -- Initialize ClickHouse database
    CREATE DATABASE IF NOT EXISTS analytics;
    
    -- Create tables for time-series data
    CREATE TABLE IF NOT EXISTS analytics.protocol_metrics_ts (
        timestamp DateTime64(3),
        protocol_id UInt32,
        protocol_name String,
        chain String,
        metric_name String,
        metric_value Float64,
        metric_unit String
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(timestamp)
    ORDER BY (protocol_id, metric_name, timestamp)
    TTL timestamp + INTERVAL 1 YEAR;
    
    -- Create table for L2 network data
    CREATE TABLE IF NOT EXISTS analytics.l2_networks (
        timestamp DateTime64(3),
        network_name String,
        network_id UInt32,
        chain_id UInt32,
        tvl Float64,
        volume_24h Float64,
        fees_24h Float64,
        active_addresses UInt32,
        total_transactions UInt64
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(timestamp)
    ORDER BY (network_name, timestamp)
    TTL timestamp + INTERVAL 1 YEAR;
    
    -- Create table for DeFi protocol events
    CREATE TABLE IF NOT EXISTS analytics.defi_events (
        timestamp DateTime64(3),
        event_type String,
        protocol_name String,
        chain String,
        user_address String,
        amount Float64,
        token_symbol String,
        transaction_hash String,
        block_number UInt64
    ) ENGINE = MergeTree()
    PARTITION BY toYYYYMM(timestamp)
    ORDER BY (protocol_name, event_type, timestamp)
    TTL timestamp + INTERVAL 1 YEAR;
    
    -- Create materialized views for common aggregations
    CREATE MATERIALIZED VIEW IF NOT EXISTS analytics.protocol_tvl_daily
    ENGINE = SummingMergeTree()
    PARTITION BY toYYYYMM(date)
    ORDER BY (protocol_name, date)
    AS SELECT
        toDate(timestamp) as date,
        protocol_name,
        chain,
        avg(metric_value) as avg_tvl,
        max(metric_value) as max_tvl,
        min(metric_value) as min_tvl
    FROM analytics.protocol_metrics_ts
    WHERE metric_name = 'tvl'
    GROUP BY date, protocol_name, chain;
